{"version":3,"sources":["App.js","index.js"],"names":["App","useState","selectedFile","setSelectedFile","videoRef","useRef","sourceRef","canvasRef","rafIdRef","detectorRef","model","modelConfig","type","scoreThreshold","style","position","top","left","right","zIndex","setupDetector","a","createDetector","runtime","split","posedetection","modelType","solutionPath","current","animate","runDetection","requestAnimationFrame","detector","video","estimatePoses","maxPoses","flipHorizontal","poses","length","ctx","getContext","clearRect","videoWidth","videoHeight","pose","drawPose","predictions","keypoints","drawKeypoints","drawSkeleton","keypointInd","getKeypointIndexBySide","middle","i","drawKeypoint","keypoint","color","score","beginPath","arc","x","y","Math","PI","fillStyle","fill","strokeStyle","lineWidth","getAdjacentPairs","forEach","j","kp1","kp2","score1","score2","moveTo","lineTo","stroke","className","onChange","event","target","files","accept","onClick","videoSource","URL","createObjectURL","src","load","ref","autoPlay","onLoadedData","width","height","translate","scale","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"iVAmKeA,MA9Jf,WAAgB,IAAD,EAC2BC,mBAAS,MADpC,mBACNC,EADM,KACQC,EADR,KAEPC,EAAWC,iBAAO,MAClBC,EAAYD,iBAAO,MACnBE,EAAYF,iBAAO,MACnBG,EAAWH,iBAAO,GAClBI,EAAcJ,iBAAO,MAKrBK,EAAQ,YACRC,EAAc,CAClBC,KAAM,OACNC,eAAgB,KAGZC,EAAQ,CACZC,SAAU,WACVC,IAAK,EACLC,KAAM,EACNC,MAAO,EACPC,OAAQ,GAaJC,EAAa,uCAAG,4BAAAC,EAAA,6DACdC,EADc,+BAAAD,EAAA,MACG,4BAAAA,EAAA,yDAEL,eADVE,EA3BM,gBA2BYC,MAAM,KAAK,IADd,yCAGZC,IAA6Bf,EAAO,CACzCa,UACAG,UAAWf,EAAYC,KACvBe,aAAc,kDANG,UAQE,SAAZJ,EARU,yCASZE,IACLf,EAAO,CAAEa,UAASG,UAAWf,EAAYC,QAVxB,2CADH,8DAeQU,IAfR,OAepBb,EAAYmB,QAfQ,OAgBpBC,IAhBoB,2CAAH,qDAmBbA,EAAU,SAAVA,IAC+B,qBAAxBpB,EAAYmB,SAAmD,OAAxBnB,EAAYmB,SAC5DE,EAAarB,EAAYmB,SAE3BpB,EAASoB,QAAUG,sBAAsBF,IAGrCC,EAAY,uCAAG,WAAOE,GAAP,yBAAAX,EAAA,6DACbY,EAAQ7B,EAASwB,QADJ,SAECI,EAASE,cAC3BD,EACA,CAAEE,SAAUxB,EAAYwB,SAAUC,gBAAgB,IAJjC,UAME,qBAJfC,EAFa,SAM2B,OAAVA,GAAmC,IAAjBA,EAAMC,OANzC,kDASbC,EAAMhC,EAAUqB,QAAQY,WAAW,OACrCC,UAAU,EAAG,EAAGR,EAAMS,WAAYT,EAAMU,aAVzB,cAWAN,GAXA,IAWnB,2BAAWO,EAAe,QACxBC,EAASD,EAAML,GAZE,0EAAH,sDAgBZM,EAAW,SAACC,EAAaP,GAC7B,IAAMQ,EAAYD,EAAYC,UAC9BC,EAAcD,EAAWR,GACzBU,EAAaF,EAAWR,IAGpBS,EAAgB,SAACD,EAAWR,GAChC,IADwC,EAClCW,EACJzB,IAAmB0B,uBAAuBzC,GAFJ,cAIxBwC,EAAYE,QAJY,IAIxC,2BAAoC,CAAC,IAA1BC,EAAyB,QAClCC,EAAaP,EAAUM,GAAI,SAAUd,IALC,kDAQxBW,EAAYjC,MARY,IAQxC,2BAAkC,CAAC,IAAxBoC,EAAuB,QAChCC,EAAaP,EAAUM,GAAI,OAAQd,IATG,kDAYxBW,EAAYhC,OAZY,IAYxC,2BAAmC,CAAC,IAAzBmC,EAAwB,QACjCC,EAAaP,EAAUM,GAAI,MAAOd,IAbI,gCAiBpCe,EAAe,SAACC,EAAUC,EAAOjB,IACL,MAAlBgB,EAASE,MAAgBF,EAASE,MAAQ,KACjC9C,EAAYE,gBAAkB,KAGnD0B,EAAImB,YACJnB,EAAIoB,IAAIJ,EAASK,EAAGL,EAASM,EAlGV,EAkG6B,EAAG,EAAIC,KAAKC,IAC5DxB,EAAIyB,UAAYR,EAChBjB,EAAI0B,SAIFhB,EAAe,SAACF,EAAWR,GAC/BA,EAAIyB,UAAY,QAChBzB,EAAI2B,YAAc,QAClB3B,EAAI4B,UA5GqB,EA8GzB1C,IAAmB2C,iBAAiB1D,GACjC2D,SAAQ,YAAa,IAAD,mBAAVhB,EAAU,KAAPiB,EAAO,KACbC,EAAMxB,EAAUM,GAChBmB,EAAMzB,EAAUuB,GAGhBG,EAAsB,MAAbF,EAAId,MAAgBc,EAAId,MAAQ,EACzCiB,EAAsB,MAAbF,EAAIf,MAAgBe,EAAIf,MAAQ,EACzC5C,EAAiBF,EAAYE,gBAAkB,EAEjD4D,GAAU5D,GAAkB6D,GAAU7D,IACxC0B,EAAImB,YACJnB,EAAIoC,OAAOJ,EAAIX,EAAGW,EAAIV,GACtBtB,EAAIqC,OAAOJ,EAAIZ,EAAGY,EAAIX,GACtBtB,EAAIsC,cAeZ,OACE,sBAAKC,UAAU,MAAf,UACE,uBAAOlE,KAAK,OAAOmE,SA3HK,SAAAC,GAC1B7E,EAAgB6E,EAAMC,OAAOC,MAAM,KA0HiBC,OAAO,YACzD,wBAAQC,QAxHc,WACxB,IAAMC,EAAcC,IAAIC,gBAAgBrF,GACxCI,EAAUsB,QAAQ4D,IAAMH,EACxBjF,EAASwB,QAAQ6D,QAqHf,oBACA,uBAAOC,IAAKtF,EAAUuF,UAAQ,EAACC,aAdvB,WACV,IAAM3D,EAAQ7B,EAASwB,QACvBrB,EAAUqB,QAAQiE,MAAQ5D,EAAMS,WAChCnC,EAAUqB,QAAQkE,OAAS7D,EAAMU,YACjC,IAAMJ,EAAMhC,EAAUqB,QAAQY,WAAW,MACzCD,EAAIwD,UAAU9D,EAAMS,WAAY,GAChCH,EAAIyD,OAAO,EAAG,GACd5E,KAOoDN,MAAOA,EAAzD,SACE,wBAAQ4E,IAAKpF,EAAWM,KAAK,gBAE/B,wBAAQ8E,IAAKnF,EAAWO,MAAOA,QCzJrCmF,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,W","file":"static/js/main.6053d870.chunk.js","sourcesContent":["import './App.css';\nimport { useRef, useState } from 'react';\nimport * as posedetection from '@tensorflow-models/pose-detection';\nimport * as tf from '@tensorflow/tfjs-core';\n\nfunction App() {\n  const [selectedFile, setSelectedFile] = useState(null);\n  const videoRef = useRef(null);\n  const sourceRef = useRef(null);\n  const canvasRef = useRef(null);\n  const rafIdRef = useRef(0);\n  const detectorRef = useRef(null);\n  const DEFAULT_LINE_WIDTH = 3;\n  const DEFAULT_RADIUS = 5;\n\n  const backend = 'mediapipe-gpu';\n  const model = 'BlazePose';\n  const modelConfig = {\n    type: 'full',\n    scoreThreshold: 0.65,\n  }\n\n  const style = {\n    position: \"absolute\",\n    top: 0,\n    left: 0,\n    right: 0,\n    zIndex: 9,\n  }\n\n  const fileSelectedHandler = event => {\n    setSelectedFile(event.target.files[0]);\n  }\n\n  const fileUploadHandler = () => {\n    const videoSource = URL.createObjectURL(selectedFile);\n    sourceRef.current.src = videoSource;\n    videoRef.current.load();\n  }\n\n  const setupDetector = async () => {\n    const createDetector = async () => {\n      const runtime = backend.split('-')[0];\n      if (runtime === 'mediapipe') {\n        return posedetection.createDetector(model, {\n          runtime,\n          modelType: modelConfig.type,\n          solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'\n        });\n      } else if (runtime === 'tfjs') {\n        return posedetection.createDetector(\n          model, { runtime, modelType: modelConfig.type });\n      }\n    }\n    \n    detectorRef.current = await createDetector();\n    animate();\n  }\n\n  const animate = () => {\n    if (typeof detectorRef.current !== \"undefined\" && detectorRef.current !== null) {\n      runDetection(detectorRef.current)\n    }\n    rafIdRef.current = requestAnimationFrame(animate);\n  }\n\n  const runDetection = async (detector) => {\n    const video = videoRef.current;\n    const poses = await detector.estimatePoses(\n      video,\n      { maxPoses: modelConfig.maxPoses, flipHorizontal: true });\n\n    if (typeof poses === 'undefined' || poses === null || poses.length === 0) {\n      return;\n    }\n    const ctx = canvasRef.current.getContext(\"2d\")\n    ctx.clearRect(0, 0, video.videoWidth, video.videoHeight);\n    for (const pose of poses) {\n      drawPose(pose, ctx)\n    }\n  }\n\n  const drawPose = (predictions, ctx) => {\n    const keypoints = predictions.keypoints;\n    drawKeypoints(keypoints, ctx)\n    drawSkeleton(keypoints, ctx)\n  }\n\n  const drawKeypoints = (keypoints, ctx) => {\n    const keypointInd =\n      posedetection.util.getKeypointIndexBySide(model);\n\n    for (const i of keypointInd.middle) {\n      drawKeypoint(keypoints[i], \"yellow\", ctx)\n    }\n\n    for (const i of keypointInd.left) {\n      drawKeypoint(keypoints[i], \"lime\", ctx)\n    }\n\n    for (const i of keypointInd.right) {\n      drawKeypoint(keypoints[i], \"red\", ctx)\n    }\n  }\n\n  const drawKeypoint = (keypoint, color, ctx) => {\n    const score = keypoint.score != null ? keypoint.score : 1;\n    const scoreThreshold = modelConfig.scoreThreshold || 0;\n\n    if (score >= scoreThreshold) {\n      ctx.beginPath();\n      ctx.arc(keypoint.x, keypoint.y, DEFAULT_RADIUS, 0, 2 * Math.PI);\n      ctx.fillStyle = color;\n      ctx.fill();\n    }\n  }\n\n  const drawSkeleton = (keypoints, ctx) => {\n    ctx.fillStyle = 'White';\n    ctx.strokeStyle = 'White';\n    ctx.lineWidth = DEFAULT_LINE_WIDTH;\n\n    posedetection.util.getAdjacentPairs(model)\n      .forEach(([i, j]) => {\n        const kp1 = keypoints[i];\n        const kp2 = keypoints[j];\n\n        // If score is null, just show the keypoint.\n        const score1 = kp1.score != null ? kp1.score : 1;\n        const score2 = kp2.score != null ? kp2.score : 1;\n        const scoreThreshold = modelConfig.scoreThreshold || 0;\n\n        if (score1 >= scoreThreshold && score2 >= scoreThreshold) {\n          ctx.beginPath();\n          ctx.moveTo(kp1.x, kp1.y);\n          ctx.lineTo(kp2.x, kp2.y);\n          ctx.stroke();\n        }\n      });\n  }\n\n  const run = () => {\n    const video = videoRef.current;\n    canvasRef.current.width = video.videoWidth;\n    canvasRef.current.height = video.videoHeight;\n    const ctx = canvasRef.current.getContext(\"2d\")\n    ctx.translate(video.videoWidth, 0);\n    ctx.scale(-1, 1);\n    setupDetector();\n  };\n\n  return (\n    <div className=\"App\">\n      <input type=\"file\" onChange={fileSelectedHandler} accept=\"video/*\"/>\n      <button onClick={fileUploadHandler}>Upload</button>\n      <video ref={videoRef} autoPlay onLoadedData={run} style={style}>\n        <source ref={sourceRef} type=\"video/mp4\"/>\n      </video>\n      <canvas ref={canvasRef} style={style}/>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n"],"sourceRoot":""}